{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "new_Decoder returned -1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-f33d8a0b138d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m     \u001b[0msd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSpeechDetector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m     \u001b[0msd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-f33d8a0b138d>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;31m# Creaders decoder object for streaming data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msetup_mic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pocketsphinx\\pocketsphinx.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDecoder\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConfig\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m         \"\"\"\n\u001b[1;32m--> 272\u001b[1;33m         \u001b[0mthis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pocketsphinx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_Decoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: new_Decoder returned -1"
     ]
    }
   ],
   "source": [
    "# this is the chibi girls code\n",
    "\n",
    "from pocketsphinx.pocketsphinx import *\n",
    "from sphinxbase.sphinxbase import *\n",
    "\n",
    "import os\n",
    "import pyaudio\n",
    "import wave\n",
    "import audioop\n",
    "from collections import deque\n",
    "import time\n",
    "import math\n",
    "\n",
    "\"\"\"\n",
    "Written by Sophie Li, 2016\n",
    "http://blog.justsophie.com/python-speech-to-text-with-pocketsphinx/\n",
    "\"\"\"\n",
    "\n",
    "class SpeechDetector:\n",
    "    def __init__(self):\n",
    "        # Microphone stream config.\n",
    "        self.CHUNK = 1024  # CHUNKS of bytes to read each time from mic\n",
    "        self.FORMAT = pyaudio.paInt16\n",
    "        self.CHANNELS = 1\n",
    "        self.RATE = 16000\n",
    "\n",
    "        self.SILENCE_LIMIT = 1  # Silence limit in seconds. The max ammount of seconds where\n",
    "                           # only silence is recorded. When this time passes the\n",
    "                           # recording finishes and the file is decoded\n",
    "\n",
    "        self.PREV_AUDIO = 0.5  # Previous audio (in seconds) to prepend. When noise\n",
    "                          # is detected, how much of previously recorded audio is\n",
    "                          # prepended. This helps to prevent chopping the beginning\n",
    "                          # of the phrase.\n",
    "\n",
    "        self.THRESHOLD = 4500\n",
    "        self.num_phrases = -1\n",
    "\n",
    "        # These will need to be modified according to where the pocketsphinx folder is\n",
    "        MODELDIR = \"../../tools/pocketsphinx/model\"\n",
    "        DATADIR = \"../../tools/pocketsphinx/test/data\"\n",
    "\n",
    "        # Create a decoder with certain model\n",
    "        config = Decoder.default_config()\n",
    "        config.set_string('-hmm', os.path.join(MODELDIR, 'en-us/en-us'))\n",
    "        config.set_string('-lm', os.path.join(MODELDIR, 'en-us/en-us.lm.bin'))\n",
    "        config.set_string('-dict', os.path.join(MODELDIR, 'en-us/cmudict-en-us.dict'))\n",
    "\n",
    "        # Creaders decoder object for streaming data.\n",
    "        self.decoder = Decoder(config)\n",
    "\n",
    "    def setup_mic(self, num_samples=50):\n",
    "        \"\"\" Gets average audio intensity of your mic sound. You can use it to get\n",
    "            average intensities while you're talking and/or silent. The average\n",
    "            is the avg of the .2 of the largest intensities recorded.\n",
    "        \"\"\"\n",
    "        print (\"Getting intensity values from mic.\")\n",
    "        p = pyaudio.PyAudio()\n",
    "        stream = p.open(format=self.FORMAT, \n",
    "                        channels=self.CHANNELS,\n",
    "                        rate=self.RATE, \n",
    "                        input=True, \n",
    "                        frames_per_buffer=self.CHUNK)\n",
    "\n",
    "        values = [math.sqrt(abs(audioop.avg(stream.read(self.CHUNK), 4)))\n",
    "                  for x in range(num_samples)]\n",
    "        values = sorted(values, reverse=True)\n",
    "        r = sum(values[:int(num_samples * 0.2)]) / int(num_samples * 0.2)\n",
    "        print (\" Finished \")\n",
    "        print (\" Average audio intensity is \", r)\n",
    "        stream.close()\n",
    "        p.terminate()\n",
    "\n",
    "        if r < 3000:\n",
    "            self.THRESHOLD = 3500\n",
    "        else:\n",
    "            self.THRESHOLD = r + 100\n",
    "\n",
    "    def save_speech(self, data, p):\n",
    "        \"\"\"\n",
    "        Saves mic data to temporary WAV file. Returns filename of saved\n",
    "        file\n",
    "        \"\"\"\n",
    "        filename = 'output_'+str(int(time.time()))\n",
    "        # writes data to WAV file\n",
    "        data = ''.join(data)\n",
    "        wf = wave.open(filename + '.wav', 'wb')\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))\n",
    "        wf.setframerate(16000)  # TODO make this value a function parameter?\n",
    "        wf.writeframes(data)\n",
    "        wf.close()\n",
    "        return filename + '.wav'\n",
    "\n",
    "    def decode_phrase(self, wav_file):\n",
    "        self.decoder.start_utt()\n",
    "        stream = open(wav_file, \"rb\")\n",
    "        while True:\n",
    "          buf = stream.read(1024)\n",
    "          if buf:\n",
    "            self.decoder.process_raw(buf, False, False)\n",
    "          else:\n",
    "            break\n",
    "        self.decoder.end_utt()\n",
    "        words = []\n",
    "        [words.append(seg.word) for seg in self.decoder.seg()]\n",
    "        return words\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Listens to Microphone, extracts phrases from it and calls pocketsphinx\n",
    "        to decode the sound\n",
    "        \"\"\"\n",
    "        self.setup_mic()\n",
    "\n",
    "        #Open stream\n",
    "        p = pyaudio.PyAudio()\n",
    "        stream = p.open(format=self.FORMAT, \n",
    "                        channels=self.CHANNELS, \n",
    "                        rate=self.RATE, \n",
    "                        input=True, \n",
    "                        frames_per_buffer=self.CHUNK)\n",
    "        print (\"* Mic set up and listening. \")\n",
    "\n",
    "        audio2send = []\n",
    "        cur_data = ''  # current chunk of audio data\n",
    "        rel = self.RATE/self.CHUNK\n",
    "        slid_win = deque(maxlen=self.SILENCE_LIMIT * rel)\n",
    "        #Prepend audio from 0.5 seconds before noise was detected\n",
    "        prev_audio = deque(maxlen=self.PREV_AUDIO * rel)\n",
    "        started = False\n",
    "\n",
    "        while True:\n",
    "            cur_data = stream.read(self.CHUNK)\n",
    "            slid_win.append(math.sqrt(abs(audioop.avg(cur_data, 4))))\n",
    "\n",
    "            if sum([x > self.THRESHOLD for x in slid_win]) > 0:\n",
    "                if started == False:\n",
    "                    print (\"Starting recording of phrase\")\n",
    "                    started = True\n",
    "                audio2send.append(cur_data)\n",
    "\n",
    "            elif started:\n",
    "                print (\"Finished recording, decoding phrase\")\n",
    "                filename = self.save_speech(list(prev_audio) + audio2send, p)\n",
    "                r = self.decode_phrase(filename)\n",
    "                print (\"DETECTED: \", r)\n",
    "\n",
    "                # Removes temp audio file\n",
    "                os.remove(filename)\n",
    "                # Reset all\n",
    "                started = False\n",
    "                slid_win = deque(maxlen=self.SILENCE_LIMIT * rel)\n",
    "                prev_audio = deque(maxlen=0.5 * rel)\n",
    "                audio2send = []\n",
    "                print (\"Listening ...\")\n",
    "\n",
    "            else:\n",
    "                prev_audio.append(cur_data)\n",
    "\n",
    "        print (\"* Done listening\")\n",
    "        stream.close()\n",
    "        p.terminate()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sd = SpeechDetector()\n",
    "    sd.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the basic recognition code\n",
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the recognizer\n",
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c94367544872>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMicrophone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Say something!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m   \u001b[0maudio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlisten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# recognize speech using Sphinx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36mlisten\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    618\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mWaitTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"listening timed out while waiting for phrase to start\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m                     \u001b[0mbuffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCHUNK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mbreak\u001b[0m  \u001b[1;31m# reached end of the stream\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m                     \u001b[0mframes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyaudio_stream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyaudio.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    606\u001b[0m                           paCanNotReadFromAnOutputOnlyStream)\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_read_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " \n",
    "with sr.Microphone() as source:  \n",
    "   print(\"Say something!\")  \n",
    "   audio = r.listen(source)  \n",
    "   \n",
    " # recognize speech using Sphinx  \n",
    "try:  \n",
    "   print(\"Sphinx thinks you said '\" + r.recognize_sphinx(audio) + \"'\")  \n",
    "except sr.UnknownValueError:  \n",
    "   print(\"Sphinx could not understand audio\")  \n",
    "except sr.RequestError as e:  \n",
    "   print(\"Sphinx error; {0}\".format(e)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/how-to-build-a-speech-recognition-bot-with-python-81d0fe3cea9a\n",
    "#this guys code\n",
    "def recognize_speech_from_mic(recognizer, microphone):\n",
    "    \"\"\"Transcribe speech from recorded from `microphone`.\n",
    "    Returns a dictionary with three keys:\n",
    "    \"success\": a boolean indicating whether or not the API request was\n",
    "               successful\n",
    "    \"error\":   `None` if no error occured, otherwise a string containing\n",
    "               an error message if the API could not be reached or\n",
    "               speech was unrecognizable\n",
    "    \"transcription\": `None` if speech could not be transcribed,\n",
    "               otherwise a string containing the transcribed text\n",
    "    \"\"\"\n",
    "    # check that recognizer and microphone arguments are appropriate type\n",
    "    if not isinstance(recognizer, sr.Recognizer):\n",
    "        raise TypeError(\"`recognizer` must be `Recognizer` instance\")\n",
    "\n",
    "    if not isinstance(microphone, sr.Microphone):\n",
    "        raise TypeError(\"`microphone` must be `Microphone` instance\")\n",
    "\n",
    "    # adjust the recognizer sensitivity to ambient noise and record audio\n",
    "    # from the microphone\n",
    "    with microphone as source:\n",
    "        recognizer.adjust_for_ambient_noise(source) # #  analyze the audio source for 1 second\n",
    "        audio = recognizer.listen(source)\n",
    "\n",
    "    # set up the response object\n",
    "    response = {\n",
    "        \"success\": True,\n",
    "        \"error\": None,\n",
    "        \"transcription\": None\n",
    "    }\n",
    "\n",
    "    # try recognizing the speech in the recording\n",
    "    # if a RequestError or UnknownValueError exception is caught,\n",
    "    #   update the response object accordingly\n",
    "    try:\n",
    "        response[\"transcription\"] = recognizer.recognize_sphinx(audio)\n",
    "    except sr.RequestError:\n",
    "        # API was unreachable or unresponsive\n",
    "        response[\"success\"] = False\n",
    "        response[\"error\"] = \"API unavailable/unresponsive\"\n",
    "    except sr.UnknownValueError:\n",
    "        # speech was unintelligible\n",
    "        response[\"error\"] = \"Unable to recognize speech\"\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    recognizer = sr.Recognizer()\n",
    "    mic = sr.Microphone(device_index=1)\n",
    "    response = recognize_speech_from_mic(recognizer, mic)\n",
    "    print('\\nSuccess : {}\\nError   : {}\\n\\nText from Speech\\n{}\\n\\n{}' \\\n",
    "          .format(response['success'],\n",
    "                  response['error'],\n",
    "                  '-'*17,\n",
    "                  response['transcription']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mp3 to text\n",
    "# importing libraries \n",
    "import speech_recognition as sr \n",
    "  \n",
    "import os \n",
    "  \n",
    "from pydub import AudioSegment \n",
    "from pydub.silence import split_on_silence \n",
    "  \n",
    "# a function that splits the audio file into chunks \n",
    "# and applies speech recognition \n",
    "#def silence_based_conversion(path = \"alice-medium.wav\"): \n",
    "def silence_based_conversion(path):  \n",
    "    # open the audio file stored in \n",
    "    # the local system as a wav file. \n",
    "    song = AudioSegment.from_wav(path) \n",
    "  \n",
    "    # open a file where we will concatenate   \n",
    "    # and store the recognized text \n",
    "    fh = open(\"recognized.txt\", \"w+\") \n",
    "          \n",
    "    # split track where silence is 0.5 seconds  \n",
    "    # or more and get chunks \n",
    "    chunks = split_on_silence(song, \n",
    "        # must be silent for at least 0.5 seconds \n",
    "        # or 500 ms. adjust this value based on user \n",
    "        # requirement. if the speaker stays silent for  \n",
    "        # longer, increase this value. else, decrease it. \n",
    "        min_silence_len = 500, \n",
    "  \n",
    "        # consider it silent if quieter than -16 dBFS \n",
    "        # adjust this per requirement \n",
    "        silence_thresh = -16\n",
    "    ) \n",
    "  \n",
    "    # create a directory to store the audio chunks. \n",
    "    try: \n",
    "        os.mkdir('audio_chunks') \n",
    "    except(FileExistsError): \n",
    "        pass\n",
    "  \n",
    "    # move into the directory to \n",
    "    # store the audio files. \n",
    "    os.chdir('audio_chunks') \n",
    "  \n",
    "    i = 0\n",
    "    # process each chunk \n",
    "    for chunk in chunks: \n",
    "              \n",
    "        # Create 0.5 seconds silence chunk \n",
    "        chunk_silent = AudioSegment.silent(duration = 10) \n",
    "  \n",
    "        # add 0.5 sec silence to beginning and  \n",
    "        # end of audio chunk. This is done so that \n",
    "        # it doesn't seem abruptly sliced. \n",
    "        audio_chunk = chunk_silent + chunk + chunk_silent \n",
    "  \n",
    "        # export audio chunk and save it in  \n",
    "        # the current directory. \n",
    "        print(\"saving chunk{0}.wav\".format(i)) \n",
    "        # specify the bitrate to be 192 k \n",
    "        audio_chunk.export(\"./chunk{0}.wav\".format(i), bitrate ='192k', format =\"wav\") \n",
    "  \n",
    "        # the name of the newly created chunk \n",
    "        filename = 'chunk'+str(i)+'.wav'\n",
    "  \n",
    "        print(\"Processing chunk \"+str(i)) \n",
    "  \n",
    "        # get the name of the newly created chunk \n",
    "        # in the AUDIO_FILE variable for later use. \n",
    "        file = filename \n",
    "  \n",
    "        # create a speech recognition object \n",
    "        r = sr.Recognizer() \n",
    "  \n",
    "        # recognize the chunk \n",
    "        with sr.AudioFile(file) as source: \n",
    "            # remove this if it is not working \n",
    "            # correctly. \n",
    "            r.adjust_for_ambient_noise(source) \n",
    "            audio_listened = r.record(source) \n",
    "  \n",
    "        try: \n",
    "            # try converting it to text \n",
    "            rec = r.recognize_google(audio_listened) \n",
    "            # write the output to the file. \n",
    "            fh.write(rec+\". \") \n",
    "  \n",
    "        # catch any errors. \n",
    "        except sr.UnknownValueError: \n",
    "            print(\"Could not understand audio\") \n",
    "  \n",
    "        except sr.RequestError as e: \n",
    "            print(\"Could not request results. check your internet connection\") \n",
    "  \n",
    "        i += 1\n",
    "  \n",
    "    os.chdir('..') \n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the audio file path\n"
     ]
    }
   ],
   "source": [
    " \n",
    "if __name__ == '__main__': \n",
    "          \n",
    "    print('Enter the audio file path') \n",
    "  \n",
    "    path = input()\n",
    "    silence_based_conversion(path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#weird ffprobe error file\\nfrom os import path\\nimport pydub\\nfrom pydub import AudioSegment\\n\\n# files                                                                         \\nsrc = r\"C:/Users/Administrator/Downloads/solitary_reaper.mp3\"\\ndst = r\"C:/Users/Administrator/Downloads/test.wav\"\\n\\n# convert wav to mp3 \\nAudioSegment.ffmpeg = \"C:/ffmpeg/bin/ffmpeg.exe\"\\nAudioSegment.ffprobe = \"C:/ffmpeg/bin/ffprobe.exe\"\\nsound = AudioSegment.from_mp3(src)\\nsound.export(dst, format=\"wav\")'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#weird ffprobe error file\n",
    "from os import path\n",
    "import pydub\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# files                                                                         \n",
    "src = r\"C:/Users/Administrator/Downloads/solitary_reaper.mp3\"\n",
    "dst = r\"C:/Users/Administrator/Downloads/test.wav\"\n",
    "\n",
    "# convert wav to mp3 \n",
    "AudioSegment.ffmpeg = \"C:/ffmpeg/bin/ffmpeg.exe\"\n",
    "AudioSegment.ffprobe = \"C:/ffmpeg/bin/ffprobe.exe\"\n",
    "sound = AudioSegment.from_mp3(src)\n",
    "sound.export(dst, format=\"wav\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport speech_recognition as sr\\nfrom os import path\\nfrom pydub import AudioSegment\\n\\n# convert mp3 file to wav    \\nAudioSegment.converter = \"C:\\\\ffmpeg\\\\bin\\\\ffmpeg.exe\"\\nAudioSegment.ffmpeg = \"C:\\\\ffmpeg\\\\bin\\\\ffmpeg.exe\"\\nAudioSegment.ffprobe =\"C:\\\\ffmpeg\\\\bin\\\\ffprobe.exe\"\\nsound = AudioSegment.from_mp3(\"C:/Users/Administrator/Downloads/solitary_reaper.mp3\")\\nsound.export(\"transcript.wav\", format=\"wav\")\\n\\n\\n# transcribe audio file                                                         \\nAUDIO_FILE = \"transcript.wav\"\\n\\n# use the audio file as the audio source                                        \\nr = sr.Recognizer()\\nwith sr.AudioFile(AUDIO_FILE) as source:\\n        audio = r.record(source)  # read the entire audio file                  \\n\\n        print(\"Transcription: \" + r.recognize_google(audio))'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#same eror pprobe\n",
    "'''\n",
    "import speech_recognition as sr\n",
    "from os import path\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# convert mp3 file to wav    \n",
    "AudioSegment.converter = \"C:\\\\ffmpeg\\\\bin\\\\ffmpeg.exe\"\n",
    "AudioSegment.ffmpeg = \"C:\\\\ffmpeg\\\\bin\\\\ffmpeg.exe\"\n",
    "AudioSegment.ffprobe =\"C:\\\\ffmpeg\\\\bin\\\\ffprobe.exe\"\n",
    "sound = AudioSegment.from_mp3(\"C:/Users/Administrator/Downloads/solitary_reaper.mp3\")\n",
    "sound.export(\"transcript.wav\", format=\"wav\")\n",
    "\n",
    "\n",
    "# transcribe audio file                                                         \n",
    "AUDIO_FILE = \"transcript.wav\"\n",
    "\n",
    "# use the audio file as the audio source                                        \n",
    "r = sr.Recognizer()\n",
    "with sr.AudioFile(AUDIO_FILE) as source:\n",
    "        audio = r.record(source)  # read the entire audio file                  \n",
    "\n",
    "        print(\"Transcription: \" + r.recognize_google(audio))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#another .wav working\n",
    "import speech_recognition as sr\n",
    "import os\n",
    " \n",
    "def main():\n",
    "    sound = r'C:\\Users\\Administrator\\Desktop\\PROJECT\\UI_design\\solitary_reaper.wav'\n",
    " \n",
    "    r = sr.Recognizer()\n",
    " \n",
    " \n",
    "    with sr.AudioFile(sound) as source:\n",
    "        r.adjust_for_ambient_noise(source)\n",
    "        audio = r.record(source)\n",
    "    os.remove(sound)\n",
    "    command=''\n",
    "    command=r.recognize_google(audio)\n",
    "    print(\"Converting Audio To Text ..... \")\n",
    "    try:\n",
    "        print(\"Sphinx thinks you said \" +command )\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Sphinx could not understand audio\")\n",
    "    except sr.RequestError as e:\n",
    "        print(\"Sphinx error; {0}\".format(e))\n",
    " \n",
    "        #audio = r.listen(source)\n",
    " \n",
    "        #print(\"Converted Audio Is : \\n\" + r.recognize_sphinx(audio))\n",
    " \n",
    " #r.recognize_google(audio)\n",
    "    #except Exception as e:\n",
    "       # print(\"Error {} : \".format(e) )\n",
    " \n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (<ipython-input-15-bf0d3c8de6d3>, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-15-bf0d3c8de6d3>\"\u001b[1;36m, line \u001b[1;32m19\u001b[0m\n\u001b[1;33m    key='xxx', 'en-US', show_all=False)\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "#different google code\n",
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer()\n",
    "\n",
    "filename = 'hello.wav'\n",
    "\n",
    "# Save audio data\n",
    "f = open(filename, 'wb+')\n",
    "f.write(sound_bytes)\n",
    "f.close()\n",
    "\n",
    "# Read audio data\n",
    "with sr.AudioFile(audio_filename) as source:\n",
    "    audio_source = r.record(source)  # read the entire audio file\n",
    "\n",
    "# Speech Recognition\n",
    "text = recognizer.recognize_google(audio_data=audio_source,\n",
    "                                               key='xxx', 'en-US', show_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/32005310/speech-recognition-python-code-not-working\n",
    "#another one\n",
    "#microphone is shit so coldbnt check\n",
    "#!/usr/bin/ python\n",
    "import time\n",
    "\n",
    "import speech_recognition as sr\n",
    "\n",
    "\n",
    "def recognize_speech_from_mic(recognizer, microphone):\n",
    "    \"\"\"Transcribe speech from recorded from `microphone`.\n",
    "\n",
    "    Returns a dictionary with three keys:\n",
    "    \"success\": a boolean indicating whether or not the API request was\n",
    "           successful\n",
    "    \"error\":   `None` if no error occured, otherwise a string containing\n",
    "           an error message if the API could not be reached or\n",
    "           speech was unrecognizable\n",
    "    \"transcription\": `None` if speech could not be transcribed,\n",
    "           otherwise a string containing the transcribed text\n",
    "    \"\"\"\n",
    "    # check that recognizer and microphone arguments are appropriate type\n",
    "    if not isinstance(recognizer, sr.Recognizer):\n",
    "        raise TypeError(\"`recognizer` must be `Recognizer` instance\")\n",
    "\n",
    "    if not isinstance(microphone, sr.Microphone):\n",
    "        raise TypeError(\"`microphone` must be `Microphone` instance\")\n",
    "\n",
    "    # adjust the recognizer sensitivity to ambient noise and record audio\n",
    "    # from the microphone\n",
    "    with microphone as source:\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = recognizer.listen(source)\n",
    "\n",
    "    # set up the response object\n",
    "    response = {\n",
    "        \"success\": True,\n",
    "        \"error\": None,\n",
    "        \"transcription\": None\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response[\"transcription\"] =    recognizer.recognize_google(audio)\n",
    "    except sr.RequestError:\n",
    "        # API was unreachable or unresponsive\n",
    "        response[\"success\"] = False\n",
    "        response[\"error\"] = \"API unavailable\"\n",
    "    except sr.UnknownValueError:\n",
    "        # speech was unintelligible\n",
    "        response[\"error\"] = \"Unable to recognize speech\"\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    NUM_GUESSES = 1\n",
    "    PROMPT_LIMIT = 2\n",
    "    # create recognizer and mic instances\n",
    "    recognizer = sr.Recognizer()\n",
    "    microphone = sr.Microphone()\n",
    "\n",
    "    word = \"hello world\"\n",
    "\n",
    "    time.sleep(3)\n",
    "\n",
    "    for i in range(NUM_GUESSES):\n",
    "        for j in range(PROMPT_LIMIT):\n",
    "            print('Guess {}. Speak!'.format(i+1))\n",
    "            guess = recognize_speech_from_mic(recognizer, microphone)\n",
    "            if guess[\"transcription\"]:\n",
    "                break\n",
    "            if not guess[\"success\"]:\n",
    "                break\n",
    "            print(\"I didn't catch that\")\n",
    "\n",
    "        # if there was an error, stop the game\n",
    "        if guess[\"error\"]:\n",
    "            print(\"ERROR: {}\".format(guess[\"error\"]))\n",
    "            break\n",
    "\n",
    "        # show the user the transcription\n",
    "        print(\"You said: {}\".format(guess[\"transcription\"]))\n",
    "\n",
    "        # determine if guess is correct and if any attempts remain\n",
    "        guess_is_correct = guess[\"transcription\"].lower() == word.lower()\n",
    "        user_has_more_attempts = i < NUM_GUESSES - 1\n",
    "\n",
    "        if guess_is_correct:\n",
    "            print(\"Correct!\".format(word))\n",
    "            break\n",
    "        elif user_has_more_attempts:\n",
    "            print(\"Incorrect. Try again.\\n\")\n",
    "        else:\n",
    "            print(\"Sorry, output is not similar to '{}'.\".format(word))\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st working model. accuracy very bad with sphinx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#https://www.programcreek.com/python/example/107718/speech_recognition.AudioFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def recognise(wavpath):\n",
    "    try:\n",
    "        # Recognize audio\n",
    "        r = sr.Recognizer()\n",
    "        with sr.AudioFile(wavpath) as source:\n",
    "            r.adjust_for_ambient_noise(source)\n",
    "            audio = r.record(source)  # read the entire audio file\n",
    "\n",
    "    except Exception as ex:\n",
    "        return str(ex)\n",
    "\n",
    "    os.remove(wavpath)\n",
    "\n",
    "    command = ''\n",
    "\n",
    "    # recognize speech using Sphinx\n",
    "    try:\n",
    "        command = r.recognize_google(audio)\n",
    "        print(\"Sphinx or google thinks you said \" + command)\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Sphinx could not understand audio\")\n",
    "    except sr.RequestError as e:\n",
    "        print(\"Sphinx error; {0}\".format(e))\n",
    "    return command \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    recognise('solitary_reaper.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##without ambient:\n",
    "Sphinx thinks you said solitary reaper by William Wordsworth\n",
    "behold the single in the field Yon solitary Highland lass reaping\n",
    "and singing by herself stop here or gently pass Alone she cuts \n",
    "and bytes grain and sayings on melancholy strain listen to the Vale\n",
    "profound is overflowing with the sound no Nightingale did efficient more welcome note\n",
    "s to very bands of Travellers in some Shady harmed among Arabian Sands a\n",
    "voice search thrilling never was heard in springtime from the\n",
    "Cuckoo bird Breaking The Silence of cys among the farthest hebrides open tell me\n",
    "what you sayings about the plaintive numbers love for cold and Happy Father of things\n",
    "and battles long ago or is it some more humble a familiar matter of \n",
    "today some natural sorrow loss of pain that has been Namibia Kane WWE\n",
    "theme the maiden sign does a first song could have no ending i-sourcing\n",
    "at home work and over the Sickle bending I listened motionless I'm still\n",
    "and as a mountain of the hill the music in my heart Viber long after it was heard no more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#with ambient:\n",
    "Sphinx thinks you said solitary reaper by William Wordsworth single in the field Yon solitary\n",
    "Highland lass reaping and singing by herself stop here adjunctive alone she cuts and bites The \n",
    "Grain and sings a melancholy strain listen to the Vale profound is overflowing with sound no \n",
    "Nightingale did efficient more welcome notes to very bands of Travellers in some share Rihand \n",
    "among Arabian Sands a voice search thrilling never was heard in springtime from the Cuckoo bird \n",
    "Breaking The Silence of cys among the farthest hebrides open tell me what she seems that the plaintive \n",
    "numbers love frozen Happy Father of things and battles long ago or is it some more humble a \n",
    "familiar matter of today some natural sorrow loss of pain that has been done maybe again what \n",
    "are the theme the maiden sign that the first song could have nerve ending I Sourcing at home \n",
    "work and out the Sickle bending I listened motion medicine still and as a mountain of the hill \n",
    "the music in my heart Viber long after it was heard no more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sphinx or google thinks you said solitary reaper by William Wordsworth behold her single in the field Yon solitary Highland lass reaping and singing by herself stop here or gently pass Alone she cuts and bites The Grain and sings a melancholy strain listen to the Vale profound is overflowing with sound no Nightingale did efficient more welcome notes to very bands of Travellers in some Shady Honth among Arabian Sands a voice search thrilling never was heard in springtime from the Cuckoo bird Breaking The Silence of cys among the farthest hebrides even tell me what she seems that the plaintive numbers love frozen Happy Father of things and battles long ago or is it summer hanbali familiar matter of today some natural sorrow loss of pain that has been done maybe again what are the theme the maiden sign that the first song could have no vending i-sourcing at home work and how vi roll bending I listened motionless I'm still and as a mountain of the hill the music in my heart Viber long after it was heard no more\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import speech_recognition as sr\n",
    "def recognise(wavpath):\n",
    "    fh = open(\"recognized.txt\", \"w+\")\n",
    "    try:\n",
    "        # Recognize audio\n",
    "        r = sr.Recognizer()\n",
    "        with sr.AudioFile(wavpath) as source:\n",
    "            r.adjust_for_ambient_noise(source)\n",
    "            audio = r.record(source)  # read the entire audio file\n",
    "\n",
    "    except Exception as ex:\n",
    "        return str(ex)\n",
    "\n",
    "    #os.remove(wavpath)\n",
    "\n",
    "    command = ''\n",
    "\n",
    "    # recognize speech using Sphinx\n",
    "    try:\n",
    "        command = r.recognize_google(audio)\n",
    "        print(\"Sphinx or google thinks you said \" + command)\n",
    "        fh.write(command+\". \") \n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Sphinx could not understand audio\")\n",
    "    except sr.RequestError as e:\n",
    "        print(\"Sphinx error; {0}\".format(e))\n",
    "    return command \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    recognise(r'C:\\Users\\shery\\Desktop\\PROJECT\\UI_Design\\solitary_reaper.wav')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shery\\Anaconda3\\lib\\site-packages\\pydub\\utils.py:193: RuntimeWarning: Couldn't find ffprobe or avprobe - defaulting to ffprobe, but may not work\n",
      "  warn(\"Couldn't find ffprobe or avprobe - defaulting to ffprobe, but may not work\", RuntimeWarning)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-f371602c092e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mffmpeg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"C:\\ffmpeg\\bin\\ffmpeg.exe\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mffprobe\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m\"C:\\ffmpeg\\bin\\ffprobe.exe\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0msound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_mp3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0msound\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"wav\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydub\\audio_segment.py\u001b[0m in \u001b[0;36mfrom_mp3\u001b[1;34m(cls, file, parameters)\u001b[0m\n\u001b[0;32m    714\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfrom_mp3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mp3'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydub\\audio_segment.py\u001b[0m in \u001b[0;36mfrom_file\u001b[1;34m(cls, file, format, codec, parameters, **kwargs)\u001b[0m\n\u001b[0;32m    663\u001b[0m             \u001b[0mstdin_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 665\u001b[1;33m         \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmediainfo_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    666\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m             audio_streams = [x for x in info['streams']\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pydub\\utils.py\u001b[0m in \u001b[0;36mmediainfo_json\u001b[1;34m(filepath)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[0mcommand\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mprober\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-of'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'json'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcommand_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstdin_parameter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m     \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstdin_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[0;32m    707\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    710\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m             \u001b[1;31m# Cleanup if the child failed starting.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m    995\u001b[0m                                          \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 997\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m    998\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m                 \u001b[1;31m# Child is launched. Close the parent's copy of those pipe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "#mp3 to wav conversion\n",
    "from os import path\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# files                                                                         \n",
    "src = \"s_r.mp3\"\n",
    "dst = \"test.wav\"\n",
    "\n",
    "# convert wav to mp3         \n",
    "AudioSegment.converter = \"C:\\ffmpeg\\bin\\ffmpeg.exe\"\n",
    "AudioSegment.ffmpeg = \"C:\\ffmpeg\\bin\\ffmpeg.exe\"\n",
    "AudioSegment.ffprobe =\"C:\\ffmpeg\\bin\\ffprobe.exe\"\n",
    "sound = AudioSegment.from_mp3(src)\n",
    "sound.export(dst, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "#for file in lst:\n",
    "# convert wav to mp3\n",
    "os.system(r\"ffmpeg -i C:\\Users\\shery\\Desktop\\PROJECT\\UI_Design\\s_r.mp3 -acodec pcm_u8 -ar 22050 C:\\Users\\shery\\Desktop\\PROJECT\\UI_Design\\s_r.wav\")  \n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
